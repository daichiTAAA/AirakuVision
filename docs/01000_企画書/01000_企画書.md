# 企画書：Thinkletを活用した映像＋音声ベース作業分析・自動化システム構想

## 1. 背景と目的

- 製造現場では、**作業手順の遵守、改善活動、品質トレーサビリティ**が求められている。
    
- 従来の要素作業分析市販ソフト（例：OTRS）は高額で、将来的なリアルタイム作業間違い判定や工程最適化などのニーズに対応しにくい。また、ウェアラブルデバイス映像の受信と録画機能は持っていない。
- 市販の動画の録画と再生ソフトウェアであるVMSは、遅延の大きいRTSPプロンプトにしか対応しておらず、将来リアルタイム作業手順判定などで必要となる低遅延プロトコルであるWebRTCが使用できない。また、要素作業分析支援にも対応していない。
- 当社では、**自社要件に最適化した内製システム**を構築し下記を実現する。
    - 低コストでの導入
    - 自社データを活用したAI高度化
    - 柔軟な現場ニーズの取り込み
        
---

## 2. 全体アーキテクチャ

### (1) デバイス側（Thinklet）

- **一人称映像**をWHIPで配信。
    
- **音声入力**：
    
    - デバイス名（例：Bright-Red）＋「開始／終了／中断／再開」＋「月連番」
        
    - 騒音環境下でも認識可能なように **ビームフォーミング** を使用。
        
    - 認識結果が曖昧な場合は **音再認識（リプロンプト）** を行い、作業者に確認して誤認識を防ぐ。
        

### (2) サーバ（MediaMTX＋業務API）

- MediaMTXで映像を受信・録画(WHIP、HLS形式）。
    
- MediamtxでWHEPでリアルタイム配信、HLSで録画再生
    
- 録画動画と工程、型式、機番、生産指示日、月連番を紐付ける
    
- API群（/v1/...）：
    
    - `/v1/work-events`：開始・終了・中断・再開のイベント登録。
        
    - `/v1/devices/{id}/status`：現在の状態や次の期待月連番を返却。
        
    - `/v1/devices/{id}/month-serial:set`：月連番の上書き。
        
- **生産順序リスト**：
    
    - `android_id` ごとに `instruction_date`（生産指示日）、`month_serial`、工程情報を管理。
        
    - 音声入力された `month_serial` が順序リストに存在するかを照合。
        
    - 古い順に進め、前月分や過去分も処理可能。
        

### (3) データ管理（Databricks）

- Deltaテーブルで以下を一元管理：
    
    - `production_sequence`（順序）
        
    - `work_events`（音声イベントログ）
        
    - `video_bindings`（映像と工程メタの紐付け）
        
- 教師データとして活用し、AIモデルを継続学習させる。
    

### (4) 要素作業分析

- Webアプリで録画動画を再生し、要素作業の開始時にクリックすることで要素作業の開始と終了時刻を取得。作業区間毎に要素作業を記載する。
    

- この手動分析データを教師データとして、AIモデルを訓練。
    
- モデル構成：
    
    - 動作分節モデル（作業開始・終了点の推定）
        
    - 要素分類モデル（作業区間の種類分類）
        
- 運用フロー：
    
    - AIが候補区間を提示。
        
    - 作業者が確認・修正。
        
    - 修正結果を再学習に反映し精度向上。
        

---

## 3. 特徴と強み

1. **低コスト内製**：自社専用に構築するためライセンス料が不要。
    
2. **音声操作×映像紐付け**：作業者は「デバイス名＋開始／終了＋月連番」を発話するだけで記録可能。
    
3. **順序の厳格管理**：生産指示日に基づき、月初に前月分を処理するケースも自然に対応可能。
    
4. **中断／再開対応**：休憩・段取り替え時に作業を一時停止し、正確な区間記録が可能。
    
5. **AIによる効率化**：手動ラベルデータを蓄積し、将来的に自動分析の精度を高められる。
    
6. **騒音対応技術**：Thinkletの**ビームフォーミング機能**により話者の声を抽出し、誤認識を低減。さらに**音再認識の仕組み**で確実性を担保。
    

---

## 4. 利用シナリオ例

1. 作業者がThinkletを装着し作業開始。
    
2. 「**ブライトレッド 開始 123**」と発話。
    
    - サーバが生産順序を特定しRUNNING状態に遷移。
        
3. 作業終了時：「**ブライトレッド 終了 123**」と発話。
    
    - 録画映像と工程メタが自動で紐付けされる。
        
4. 騒音下で誤認識した場合、TTSで「**123ですか？**」と確認 → 再入力可能。
    
5. AIが候補区間を自動抽出、確認UIで人が修正 → 日々精度向上。
    

---

## 5. 開発ステップ（ロードマップ）

- **フェーズ1（3か月）**：
    
    - MVP開発：映像配信・録画・音声イベント送信・CSV出力。
        
    - 生産順序リストと月連番の紐付け実装。
        
- **フェーズ2（6か月）**：
    
    - 中断／再開機能、日本語ASR最適化、音再認識の追加。
        
    - Databricks連携による映像＋工程データの可視化。
        
- **フェーズ3（12か月〜）**：
    
    - AIモデル試験導入（候補提示型）。
        
    - 精度評価と改善サイクル構築。
        

---

## 6. 想定効果

- **省力化**：作業記録を音声と映像で自動化。
    
- **品質保証**：映像証跡と工程データが常に紐付く。
    
- **改善活動**：要素時間の可視化によりボトルネックを特定。
    
- **AI活用**：データ蓄積によって現場特化のAIモデルが進化。
    
- **誤認識抑止**：ビームフォーミング＋音再認識で騒音環境下でも安定利用可能。
    

---

## 7. 結論

本構想は、**Thinkletの映像＋音声入力を活用し、低コストで精度の高い作業分析システム**を自社内に構築するものである。騒音環境下でもビームフォーミングと音再認識により安定した音声入力が可能で、将来的にはAIによる自動要素作業分析に発展可能である。